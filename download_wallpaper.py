# -*- coding: utf-8 -*-
"""
Bing Wallpaper Downloader for GitHub Actions (Final Robust Version)
- This script is a fusion of the original powerful script and best practices for cloud automation.
- It robustly finds the download link and saves the image with a fixed filename.
Author: Guohonglie (Refactored by AI for Actions)
Date: 2025-09-04
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from urllib.parse import urljoin
import sys

# --- é…ç½®åŒºåŸŸ ---
# è¾“å‡ºçš„æ–‡ä»¶åï¼ˆå›ºå®šä¸å˜ï¼Œç”¨äºåœ¨GitHubä»“åº“ä¸­è¦†ç›–ï¼‰
OUTPUT_FILENAME = "daily-wallpaper.jpg"
# è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
}

def find_download_link(soup, page_url):
    """
    (æ¥è‡ªæ‚¨çš„åŸå§‹ä»£ç ) æŸ¥æ‰¾ä¸‹è½½é“¾æ¥çš„å¼ºå¤§å‡½æ•°ã€‚
    å®ƒç»“åˆäº†ä¸¤ç§ç­–ç•¥ï¼Œä»¥ç¡®ä¿æœ€å¤§å¯èƒ½åœ°æ‰¾åˆ°é“¾æ¥ã€‚
    """
    # æ–¹æ³•1: æŸ¥æ‰¾æ–‡æœ¬ä¸­åŒ…å« "4k", "download" ç­‰å…³é”®è¯çš„ä¸‹è½½æŒ‰é’®
    for link in soup.find_all('a', href=True):
        href = link.get('href')
        text = link.get_text().strip().lower()
        if any(keyword in text for keyword in ['4k', 'download', 'uhd', 'ä¸‹è½½']):
            if 'storage/bing-wallpapers/' in href:
                full_url = urljoin(page_url, href)
                print(f"  âœ… [ç­–ç•¥1] é€šè¿‡ä¸‹è½½æŒ‰é’®æ‰¾åˆ°é“¾æ¥: {full_url}")
                return full_url

    # æ–¹æ³•2: å¦‚æœæ‰¾ä¸åˆ°æŒ‰é’®ï¼Œå°±ç›´æ¥åœ¨é¡µé¢çš„å›¾ç‰‡(img)æ ‡ç­¾é‡Œå¯»æ‰¾
    for img in soup.find_all('img'):
        src = img.get('src', '')
        if 'bing-wallpapers' in src:
            full_url = urljoin(page_url, src)
            print(f"  âœ… [ç­–ç•¥2] é€šè¿‡å›¾ç‰‡æ ‡ç­¾æ‰¾åˆ°é“¾æ¥: {full_url}")
            return full_url

    return None

def download_image(image_url, output_filename):
    """ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„"""
    try:
        print(f"  ğŸ“¥ æ­£åœ¨ä¸‹è½½å›¾ç‰‡...")
        response = requests.get(image_url, headers=HEADERS, stream=True, timeout=30)
        response.raise_for_status()
        with open(output_filename, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        print(f"  ğŸ‘ å›¾ç‰‡ '{output_filename}' ä¸‹è½½å¹¶ä¿å­˜æˆåŠŸ!")
        return True
    except requests.exceptions.RequestException as e:
        print(f"  âŒ ä¸‹è½½å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    # BingWallsçš„å£çº¸é€šå¸¸æ˜¯å‰ä¸€å¤©çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è·å–æ˜¨å¤©çš„æ—¥æœŸ
    # ä½¿ç”¨ UTC æ—¶é—´ï¼Œå› ä¸º GitHub Actions çš„æœåŠ¡å™¨é€šå¸¸ä½¿ç”¨ UTC
    yesterday_utc = datetime.utcnow() - timedelta(days=1)
    date_str = yesterday_utc.strftime("%Y-%m-%d") # ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ï¼Œè¿™åœ¨æ‚¨çš„åŸå§‹ä»£ç ä¸­æ˜¯æœ‰æ•ˆçš„

    page_url = f"https://bingwalls.com/china/{date_str}"
    
    print(f"ğŸš€ å¼€å§‹å¤„ç†æ—¥æœŸ (UTC): {date_str}")
    print(f"ğŸ“„ æ­£åœ¨è®¿é—®é¡µé¢: {page_url}")

    try:
        response = requests.get(page_url, headers=HEADERS, timeout=15)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ä½¿ç”¨æ‚¨åŸå§‹ä»£ç ä¸­çš„å¼ºå¤§æŸ¥æ‰¾å‡½æ•°
        download_url = find_download_link(soup, page_url)

        if not download_url:
            print("  âŒ æœªèƒ½åœ¨é¡µé¢ä¸Šæ‰¾åˆ°æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥ã€‚")
            sys.exit(1)

        if not download_image(download_url, OUTPUT_FILENAME):
            sys.exit(1)

        print("ğŸ‰ ä»»åŠ¡æˆåŠŸå®Œæˆï¼")

    except requests.exceptions.RequestException as e:
        # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼ŒåŒ…æ‹¬çŠ¶æ€ç 
        error_message = f"  âŒ è®¿é—®é¡µé¢æ—¶å‘ç”Ÿé”™è¯¯: {e}"
        if e.response is not None:
            error_message += f" (Status Code: {e.response.status_code})"
        print(error_message)
        sys.exit(1)

if __name__ == "__main__":
    main()
